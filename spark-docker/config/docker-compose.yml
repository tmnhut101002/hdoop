version: '3.7'

services:
  spark-master:
    image: bitnami/spark:latest
    command: /opt/bitnami/spark/scripts/config/install_and_start.sh
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes:
      - /home/hdoop/spark-docker:/opt/bitnami/spark/scripts

  spark-worker-1:
    image: bitnami/spark:latest
    command: /opt/bitnami/spark/scripts/config/install_and_start.sh
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_MASTER_URL: spark://spark-master:7077
    volumes:
      - /home/hdoop/spark-docker:/opt/bitnami/spark/scripts

  spark-worker-2:
    image: bitnami/spark:latest
    command: /opt/bitnami/spark/scripts/config/install_and_start.sh
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_MASTER_URL: spark://spark-master:7077
    volumes:
      - /home/hdoop/spark-docker:/opt/bitnami/spark/scripts

  namenode:
    image: apache/hadoop:3.3.6
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./config
    environment:
        ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
  
  datanode:
    image: apache/hadoop:3.3.6
    command: ["hdfs", "datanode"]
    env_file:
      - ./config      
  
  resourcemanager:
    image: apache/hadoop:3.3.6
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
        - 8088:8088
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
  
  nodemanager:
    image: apache/hadoop:3.3.6
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config
